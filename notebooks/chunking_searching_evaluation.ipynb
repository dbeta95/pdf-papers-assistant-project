{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking and search algorithms test\n",
    "\n",
    "preprocessing strategies to split our documents into chunks:\n",
    "\n",
    "* Sentences splitting\n",
    "* Semantic chunking\n",
    "* Sequential semantic chunking\n",
    "\n",
    "On the other hand, we contemplate three retrieval scenarios, implemented directly in code (the expected volume of data for this projects is not big enough for a vector DB to be neccesary and the implementation is usefull for concepts understanding):\n",
    "\n",
    "* Word matching using TFid vectorizer (as seen in the course in the minsearch implementation)\n",
    "* Hybrid serach implementing the embeddings with sentence transformers.\n",
    "* Hybrid search with RRF.\n",
    "\n",
    "This notebooks compares the capability of each scenario to create a good retrieval strategy. Though verifying the end to end behavior by evaluating the final RAG response with each metodology would be more recommendable in the optimization process, given time restrictions we will only explore the performance and use the MMR to optimize the hyperparameters using a ground_truth data base generated for each chunkig strategy. Given the best parameters for the best performing search method for each chunking alternative we will compare the chunking strategies in a future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Cursos\\llm_zoomcamp_final_project\\llm-project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(project_path)\n",
    "\n",
    "from src.rag import RAG\n",
    "from src.evaluation import evaluate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to check the performance of our search arlgorithms using the ground truth dataset. For this we will evaluate both our minsearch (word matching) and hybridsearch (word matching and semantic search) with each set of chunks and ground truth data. Notice that since rrf is a parameter of our hybridserach approach we are evaluating it withing the optimization process to get the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data indexing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains: 2929 sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'Attention Is All You Need\\nAshish Vaswani\\x03\\nGoogle Brain\\navaswani@google.comNoam Shazeer\\x03\\nGoogle Brain\\nnoam@google.comNiki Parmar\\x03\\nGoogle Research\\nnikip@google.comJakob Uszkoreit\\x03\\nGoogle Research\\nusz@google.com\\nLlion Jones\\x03\\nGoogle Research\\nllion@google.comAidan N. Gomez\\x03y\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser\\x03\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin\\x03z\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-2',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-3',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence_splitting = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'sentence_splitting.csv')\n",
    ")\n",
    "print(f\"The data set contains: {df_sentence_splitting.shape[0]} sentences\")\n",
    "sentece_splitting_docs = df_sentence_splitting.to_dict(orient=\"records\")\n",
    "sentece_splitting_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Cursos\\llm_zoomcamp_final_project\\llm-project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialice the RAG\n",
    "ss_rag = RAG(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Define search fields\n",
    "text_fields = [\n",
    "    'category',\n",
    "    'paper',\n",
    "    'text'\n",
    "]\n",
    "keyword_fields = ['id']\n",
    "\n",
    "# Ingest the documents\n",
    "ss_rag.minsearch_index(\n",
    "    docs=sentece_splitting_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")\n",
    "ss_rag.hybserach_index(\n",
    "    docs=sentece_splitting_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that both algorithms are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'What specific architectural or training techniques enabled the model to achieve such a significant BLEU score improvement compared to previous single models?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-157',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41:0,\\noutperforming all of the previously published single models, at less than 1=4the training cost of the\\nprevious state-of-the-art model.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-6',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_rag.minsearch(query, num_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-6',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-157',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41:0,\\noutperforming all of the previously published single models, at less than 1=4the training cost of the\\nprevious state-of-the-art model.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_rag.hybsearch(query, num_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-157',\n",
       "  'question': 'What specific architectural or training techniques enabled the model to achieve such a significant BLEU score improvement compared to previous single models?'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-157',\n",
       "  'question': 'How does the reduced training cost of this model compare to the cost of ensemble models, and what are the trade-offs involved in choosing one over the other?'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-157',\n",
       "  'question': \"What are the limitations of the model's performance on the WMT 2014 English-to-French translation task, and how might these be addressed in future research?\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ss_gt = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'ground-truth-sentence-splitting.csv')\n",
    ")\n",
    "ss_gt_docs = df_ss_gt.to_dict(orient=\"records\")\n",
    "ss_gt_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by evaluating the arlgorithms with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 372.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.43636363636363634, 'mmr': 0.34350803957946807}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ss_gt_docs, lambda q: ss_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:39<00:00,  7.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.4688311688311688, 'mmr': 0.34527674706246125}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ss_gt_docs, lambda q: ss_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the minserach_fit and hybserach_fit methods implemented within the RAG class that use a simple optimization process (by doing a random search within the parameters space) to find the best parameters for each search algorithm. The best parameters for the algorithm with the best performance will be saved for the comparison of the RAG's performance with each chunkig stragey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 339.70it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 346.70it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 340.72it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 326.32it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 337.49it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 352.53it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 347.49it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 357.86it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 352.17it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 353.28it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.30it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 366.18it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 370.29it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 369.46it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 370.16it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 373.28it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.22it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 371.47it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 378.09it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 357.89it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 364.73it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 369.83it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 370.71it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 375.93it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 369.30it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 370.14it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 375.04it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 377.14it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 362.49it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.40it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.96it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.13it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 376.04it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.87it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 365.38it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 307.68it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 299.12it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 222.41it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 305.24it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 286.22it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 316.56it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 328.57it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 322.88it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 309.82it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 306.54it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 322.67it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 343.59it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 343.31it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 323.30it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 346.78it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 356.88it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 353.72it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 354.50it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 348.23it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.59it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.58it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.51it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 349.99it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 350.82it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 350.45it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.95it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.74it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 335.10it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 319.42it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 340.90it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 353.29it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 365.53it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 364.67it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 365.82it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.84it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 364.42it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 369.01it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.78it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 366.37it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 365.62it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 362.05it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.15it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 364.32it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 335.81it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.92it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 353.47it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 369.06it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 348.88it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 355.73it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 370.05it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 379.32it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 366.92it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 367.10it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.54it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.15it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 356.78it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.98it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 367.07it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 244.24it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 294.94it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 347.89it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 323.60it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 352.69it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 363.98it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 343.64it/s]\n",
      "100%|██████████| 100/100 [03:41<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 1.3363782475591928, 'paper': 1.723769131509511, 'text': 1.4854316318119176}\n",
      "Best score was:\n",
      "0.34350803957946807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0)\n",
    "}\n",
    "ss_rag.minserach_fit(ground_truth=ss_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:42<00:00,  7.55it/s]\n",
      "100%|██████████| 770/770 [01:40<00:00,  7.68it/s]]\n",
      "100%|██████████| 770/770 [01:39<00:00,  7.75it/s]]\n",
      "100%|██████████| 770/770 [01:39<00:00,  7.74it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.94it/s] \n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.07it/s]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.94it/s]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.86it/s]]\n",
      "100%|██████████| 770/770 [01:39<00:00,  7.73it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.91it/s]]\n",
      "100%|██████████| 770/770 [01:41<00:00,  7.58it/s]]\n",
      "100%|██████████| 770/770 [01:43<00:00,  7.41it/s]]\n",
      "100%|██████████| 770/770 [01:42<00:00,  7.51it/s]t]\n",
      "100%|██████████| 770/770 [01:49<00:00,  7.06it/s]t]\n",
      "100%|██████████| 770/770 [01:45<00:00,  7.31it/s]t]\n",
      "100%|██████████| 770/770 [01:45<00:00,  7.30it/s]t]\n",
      "100%|██████████| 770/770 [01:47<00:00,  7.18it/s]t]\n",
      "100%|██████████| 770/770 [01:51<00:00,  6.88it/s]t]\n",
      "100%|██████████| 770/770 [01:42<00:00,  7.52it/s]t]\n",
      "100%|██████████| 770/770 [01:38<00:00,  7.83it/s]t]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.04it/s]t]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.10it/s]t]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.12it/s]] \n",
      "100%|██████████| 770/770 [01:34<00:00,  8.15it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.08it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.08it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.98it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.96it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  8.02it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.02it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.09it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.07it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.09it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.14it/s]it]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.96it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.08it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.09it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.12it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.10it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.16it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.08it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.11it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.02it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.13it/s]it]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.16it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.08it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.06it/s]it]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.07it/s]it]\n",
      "100%|██████████| 770/770 [01:41<00:00,  7.61it/s]it]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.91it/s]]  \n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.97it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.04it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.03it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  8.00it/s]]\n",
      "100%|██████████| 770/770 [01:35<00:00,  8.05it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.97it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.95it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.87it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.94it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.94it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.96it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  8.00it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.92it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.96it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.92it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.93it/s]]\n",
      "100%|██████████| 770/770 [01:38<00:00,  7.81it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.93it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.94it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.93it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.95it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.95it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.93it/s]]\n",
      "100%|██████████| 770/770 [01:38<00:00,  7.85it/s]]\n",
      "100%|██████████| 770/770 [01:38<00:00,  7.86it/s]]\n",
      "100%|██████████| 770/770 [01:38<00:00,  7.84it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.88it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.89it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.94it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.92it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.95it/s]]\n",
      "100%|██████████| 770/770 [01:36<00:00,  7.95it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.93it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.91it/s]]\n",
      "100%|██████████| 100/100 [2:42:11<00:00, 97.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 2.929045533967244, 'paper': 2.948397953982448, 'text': 2.73834686069514, 'alpha': 0.1003540150371196, 'rrf': 0, 'k': 86}\n",
      "Best score was:\n",
      "0.3673907441764584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0),\n",
    "    'alpha': (0.0, 1.0),\n",
    "    'rrf': (False, True),\n",
    "    'k': (30, 100)\n",
    "}\n",
    "ss_rag.hybsearch_fit(ground_truth=ss_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 1.3363782475591928,\n",
       " 'paper': 1.723769131509511,\n",
       " 'text': 1.4854316318119176}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best minsearch parameters\n",
    "ss_rag.boost_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 346.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.43636363636363634, 'mmr': 0.34350803957946807}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(ss_gt_docs, lambda q: ss_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost_dict': {'category': 2.929045533967244,\n",
       "  'paper': 2.948397953982448,\n",
       "  'text': 2.73834686069514},\n",
       " 'alpha': 0.1003540150371196,\n",
       " 'rrf': 0,\n",
       " 'k': 86}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hybsearch parameters\n",
    "ss_h_best_params = {\n",
    "    \"boost_dict\":ss_rag.h_boost_dict,\n",
    "    \"alpha\":ss_rag.alpha,\n",
    "    \"rrf\":ss_rag.rrf,\n",
    "    \"k\":ss_rag.k\n",
    "}\n",
    "ss_h_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:38<00:00,  7.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.4662337662337662, 'mmr': 0.3673907441764584}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(ss_gt_docs, lambda q: ss_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:37<00:00,  7.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5025974025974026, 'mmr': 0.36991665767142207}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ss_gt_docs, lambda q: ss_rag.hybsearch(q['question'], num_results=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best parameters:\n",
    "\n",
    "The algorithm with best performance was the hybrid search and next we save it's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_params_file = os.path.join(project_path, 'src', 'parameters', 'ss_best_params.json')\n",
    "with open(ss_params_file, \"w\") as file:\n",
    "    json.dump(ss_h_best_params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic chunking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains: 269 sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'We used a beam size of 21and\\x0b= 0:3\\nfor both WSJ only and the semi-supervised setting.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-2',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'The Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers.'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-3',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': '[4]Jianpeng Cheng, Li Dong, and Mirella Lapata.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_semantic_chunking = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'semantic_chunking.csv')\n",
    ")\n",
    "print(f\"The data set contains: {df_semantic_chunking.shape[0]} sentences\")\n",
    "sc_docs = df_semantic_chunking.to_dict(orient=\"records\")\n",
    "sc_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Cursos\\llm_zoomcamp_final_project\\llm-project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialice the RAG\n",
    "sc_rag = RAG(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Define search fields\n",
    "text_fields = [\n",
    "    'category',\n",
    "    'paper',\n",
    "    'text'\n",
    "]\n",
    "keyword_fields = ['id']\n",
    "\n",
    "# Ingest the documents\n",
    "sc_rag.minsearch_index(\n",
    "    docs=sc_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")\n",
    "sc_rag.hybserach_index(\n",
    "    docs=sc_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-31',\n",
       "  'question': \"What are the key differences between the research presented in the papers cited with the 'CoRR' prefix and those published by Curran Associates, Inc.?\"},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-31',\n",
       "  'question': \"How do the papers cited with 'abs/1409.0473' and 'abs/1703.03906' contribute to the development of the attention mechanism in deep learning?\"},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-31',\n",
       "  'question': \"What are the potential implications of the research presented in 'abs/1406.1078' and 'abs/1412.3555' for the field of natural language processing?\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sc_gt = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'ground-truth-semantic-chunking.csv')\n",
    ")\n",
    "sc_gt_docs = df_sc_gt.to_dict(orient=\"records\")\n",
    "sc_gt_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 420.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7077922077922078, 'mmr': 0.5527313955885382}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(sc_gt_docs, lambda q: sc_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:24<00:00,  9.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7376623376623377, 'mmr': 0.5253035456606884}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(sc_gt_docs, lambda q: sc_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:02<00:00, 337.27it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 355.03it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 332.98it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 324.46it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 343.27it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 264.73it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 237.72it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 231.69it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 274.75it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 311.82it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 297.83it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 322.06it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 326.08it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 352.67it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 360.10it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 364.58it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 362.82it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 299.19it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 242.79it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 245.34it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 246.22it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 287.90it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 243.71it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 239.62it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 239.94it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 237.34it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 227.91it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 228.96it/s]\n",
      "100%|██████████| 770/770 [00:03<00:00, 232.21it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 265.32it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 269.49it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 320.70it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 366.02it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 368.38it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 359.08it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 337.37it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 356.81it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 379.59it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.35it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.07it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.94it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 378.93it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.39it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 400.10it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 407.06it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.77it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 382.22it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 410.09it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.26it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 397.17it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 401.06it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 396.73it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 396.01it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 406.72it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 413.93it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.61it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 408.31it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.99it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 408.83it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 418.75it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 413.82it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 415.77it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 412.52it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 407.88it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 407.73it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 411.87it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 414.21it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 419.68it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 418.44it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 419.07it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 403.70it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 418.63it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.99it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 385.39it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 358.26it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 367.12it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 372.44it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 371.46it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 366.85it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.87it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.75it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 405.00it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 407.42it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 408.46it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.09it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 407.98it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 409.35it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 397.08it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.22it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.93it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 412.91it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 412.76it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.42it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 413.14it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 418.73it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 403.95it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 419.22it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 413.57it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 423.12it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 406.57it/s]\n",
      "100%|██████████| 100/100 [03:39<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 0.9353338909809019, 'paper': 2.471768789824002, 'text': 2.815544505155288}\n",
      "Best score was:\n",
      "0.5527313955885382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0)\n",
    "}\n",
    "sc_rag.minserach_fit(ground_truth=sc_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:31<00:00,  8.44it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.58it/s]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.02it/s]\n",
      "100%|██████████| 770/770 [01:24<00:00,  9.09it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.05it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.02it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.97it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.03it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.02it/s]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.02it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.99it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.89it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.01it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.99it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.02it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.94it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.01it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.99it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.93it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.98it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.97it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.95it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.01it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.95it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.91it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:33<00:00,  8.22it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.96it/s]]\n",
      "100%|██████████| 770/770 [01:24<00:00,  9.09it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  9.06it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.94it/s]]\n",
      "100%|██████████| 770/770 [01:25<00:00,  8.98it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.93it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.89it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.95it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.94it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.91it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.93it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.91it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.94it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.92it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.89it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.78it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.85it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.92it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]it]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.89it/s]]  \n",
      "100%|██████████| 770/770 [01:26<00:00,  8.91it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.91it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.75it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.88it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.88it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.86it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.74it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.86it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.86it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.87it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.86it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.70it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.83it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.86it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.77it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.90it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.67it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.78it/s]]\n",
      "100%|██████████| 100/100 [2:24:31<00:00, 86.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 2.4542322611256355, 'paper': 1.4225317885901219, 'text': 1.9479982311584607, 'alpha': 0.1780985829329771, 'rrf': 0, 'k': 67}\n",
      "Best score was:\n",
      "0.5758508554937124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0),\n",
    "    'alpha': (0.0, 1.0),\n",
    "    'rrf': (False, True),\n",
    "    'k': (30, 100)\n",
    "}\n",
    "sc_rag.hybsearch_fit(ground_truth=sc_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 0.9353338909809019,\n",
       " 'paper': 2.471768789824002,\n",
       " 'text': 2.815544505155288}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best minsearch parameters\n",
    "sc_rag.boost_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 388.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7077922077922078, 'mmr': 0.5527313955885382}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(sc_gt_docs, lambda q: sc_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost_dict': {'category': 2.4542322611256355,\n",
       "  'paper': 1.4225317885901219,\n",
       "  'text': 1.9479982311584607},\n",
       " 'alpha': 0.1780985829329771,\n",
       " 'rrf': 0,\n",
       " 'k': 67}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hybsearch parameters\n",
    "sc_h_best_params = {\n",
    "    \"boost_dict\":sc_rag.h_boost_dict,\n",
    "    \"alpha\":sc_rag.alpha,\n",
    "    \"rrf\":sc_rag.rrf,\n",
    "    \"k\":sc_rag.k\n",
    "}\n",
    "sc_h_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.17*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 395.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7077922077922078, 'mmr': 0.5527313955885382}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(sc_gt_docs, lambda q: sc_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_params_file = os.path.join(project_path, 'src', 'parameters', 'sc_best_params.json')\n",
    "with open(sc_params_file, \"w\") as file:\n",
    "    json.dump(sc_h_best_params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential semantic chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data idexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains: 154 sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Unnamed: 0': 0,\n",
       "  'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'Attention Is All You Need\\nAshish Vaswani\\x03\\nGoogle Brain\\navaswani@google.comNoam Shazeer\\x03\\nGoogle Brain\\nnoam@google.comNiki Parmar\\x03\\nGoogle Research\\nnikip@google.comJakob Uszkoreit\\x03\\nGoogle Research\\nusz@google.com\\nLlion Jones\\x03\\nGoogle Research\\nllion@google.comAidan N. Gomez\\x03y\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser\\x03\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin\\x03z\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder.\\nThe best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism.\\nWe propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely.\\nExperiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train.\\nOur model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU.\\nOn the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\nWe show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\n\\x03Equal contribution.\\nListing order is random.\\nJakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea.\\nAshish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work.\\nNoam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail.\\nNiki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor.\\nLlion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations.\\nLukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nyWork performed while at Google Brain.\\nzWork performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v5  [cs.CL]  6 Dec 2017transduction problems such as language modeling and machine translation [ 35,2,5].\\nNumerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences.\\nAligning the positions to steps in computation time, they generate a sequence of hidden\\nstatesht, as a function of the previous hidden state ht'},\n",
       " {'Unnamed: 0': 1,\n",
       "  'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-2',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0;xW 1+b1)W2+b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer.\\nAnother way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512 , and the inner-layer has dimensionality\\ndff= 2048 .\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel.\\nWe also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities.\\nIn\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [ 30].\\nIn the embedding layers, we multiply those weights bypdmodel.\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\n5Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types.\\nnis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2\\x01d) O(1) O(1)\\nRecurrent O(n\\x01d2) O(n) O(n)\\nConvolutional O(k\\x01n\\x01d2)O(1) O(logk(n))\\nSelf-Attention (restricted) O(r\\x01n\\x01d)O(1) O(n=r)\\ntokens in the sequence.\\nTo this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks.\\nThe positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed.\\nThere are many choices of positional encodings,\\nlearned and ﬁxed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos;2i)=sin(pos=100002i=d model)\\nPE(pos;2i+1)=cos(pos=100002i=d model)\\nwhereposis the position and iis the dimension.\\nThat is, each dimension of the positional encoding\\ncorresponds to a sinusoid.\\nThe wavelengths form a geometric progression from 2\\x19to10000\\x012\\x19.\\nWe\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k,PEpos+kcan be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [ 9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)).\\nWe chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1;:::;x n)to another sequence of equal length (z1;:::;z n), withxi;zi2Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder.\\nMotivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer.\\nAnother is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network.\\nLearning long-range\\ndependencies is a key challenge in many sequence transduction tasks.\\nOne key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network.\\nThe shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [ 12].\\nHence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n)sequential operations.\\nIn terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlengthnis smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [ 31] representations.\\nTo improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\\n6the input sequence centered around the respective output position.\\nThis would increase the maximum\\npath length to O(n=r).\\nWe plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k<n does not connect all pairs of input and output\\npositions.\\nDoing so requires a stack of O(n=k)convolutional layers in the case of contiguous kernels,\\norO(logk(n))in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network.\\nConvolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k\\x01n\\x01d+n\\x01d2).\\nEven with k=n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models.\\nWe inspect attention distributions\\nfrom our models and present and discuss examples in the appendix.\\nNot only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs.\\nSentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens.\\nFor English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [ 38].\\nSentence pairs were batched together by approximate sequence length.\\nEach training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs.\\nFor our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds.'},\n",
       " {'Unnamed: 0': 2,\n",
       "  'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-3',\n",
       "  'category': 'deeplearning',\n",
       "  'paper': 'attention_is_all_you_need.pdf',\n",
       "  'text': 'We\\ntrained the base models for a total of 100,000 steps or 12 hours.\\nFor our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds.\\nThe big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [ 20] with\\x0c1= 0:9,\\x0c2= 0:98and\\x0f= 10'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sequential_semantic_chunking = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'sequential_semantic_chunking.csv')\n",
    ")\n",
    "print(f\"The data set contains: {df_sequential_semantic_chunking.shape[0]} sentences\")\n",
    "ssc_docs = df_sequential_semantic_chunking.to_dict(orient=\"records\")\n",
    "ssc_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Cursos\\llm_zoomcamp_final_project\\llm-project\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialice the RAG\n",
    "ssc_rag = RAG(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Define search fields\n",
    "text_fields = [\n",
    "    'category',\n",
    "    'paper',\n",
    "    'text'\n",
    "]\n",
    "keyword_fields = ['id']\n",
    "\n",
    "# Ingest the documents\n",
    "ssc_rag.minsearch_index(\n",
    "    docs=ssc_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")\n",
    "ssc_rag.hybserach_index(\n",
    "    docs=ssc_docs,\n",
    "    text_fields=text_fields,\n",
    "    keyword_fields=keyword_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'question': 'What specific challenges or limitations of recurrent neural networks in sequence transduction tasks are addressed by the Transformer architecture, and how does the reliance on attention mechanisms overcome these limitations?'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'question': 'The paper mentions that the Transformer model achieves superior performance in machine translation tasks. What specific aspects of the Transformer architecture contribute to this improved quality, and how do they differ from traditional encoder-decoder models?'},\n",
       " {'id': 'e1ccff07e5c99304d9674e3bb8b21a9f3ad63a708349704476b45c169163a8b4-1',\n",
       "  'question': 'The Transformer architecture is described as being more parallelizable than recurrent models. Explain how this parallelization is achieved and what implications it has for training efficiency and scalability.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssc_gt = pd.read_csv(\n",
    "    os.path.join(project_path, 'data', 'testing', 'ground-truth-sequential-semantic-chunking.csv')\n",
    ")\n",
    "ssc_gt_docs = df_ssc_gt.to_dict(orient=\"records\")\n",
    "ssc_gt_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 399.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6506493506493507, 'mmr': 0.4196438878581736}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ssc_gt_docs, lambda q: ssc_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:28<00:00,  8.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7298701298701299, 'mmr': 0.47098433312718985}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ssc_gt_docs, lambda q: ssc_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 385.92it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.00it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 377.98it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 383.66it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 387.12it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 405.95it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 396.40it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.29it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 396.09it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 387.14it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.73it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 406.25it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 388.67it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 403.78it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.05it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.41it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.82it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.06it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 402.47it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 389.39it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 408.99it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 397.40it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 350.60it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 367.06it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 397.14it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 396.94it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 382.77it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 406.01it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 402.62it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.56it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.27it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 389.83it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 402.72it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.94it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 388.62it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.46it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 367.94it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 376.49it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 387.14it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 384.69it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 399.79it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.82it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 385.95it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 386.30it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 387.08it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.65it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.97it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.15it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 386.25it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.46it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.14it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.27it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.14it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.32it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.57it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.68it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 393.83it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.17it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 384.89it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 389.63it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 381.40it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.24it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.58it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.62it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.25it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.32it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.12it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 401.31it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 388.68it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.36it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 398.61it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.09it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 377.73it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 389.73it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 383.94it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.88it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.61it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 388.77it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 385.60it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 384.35it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.60it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 383.76it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 383.21it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 403.34it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 390.34it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 387.30it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 397.33it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 381.45it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 392.31it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 381.36it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 402.19it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 378.76it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 376.92it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 391.72it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 394.72it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 395.72it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 401.58it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 404.78it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 378.27it/s]\n",
      "100%|██████████| 770/770 [00:02<00:00, 377.83it/s]\n",
      "100%|██████████| 100/100 [03:17<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 0.08962309625236509, 'paper': 1.5419571656285616, 'text': 1.0558143115463618}\n",
      "Best score was:\n",
      "0.4196438878581736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0)\n",
    "}\n",
    "ssc_rag.minserach_fit(ground_truth=ssc_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:30<00:00,  8.52it/s]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.55it/s]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.41it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.56it/s]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.51it/s]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.53it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.58it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.57it/s]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.54it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.58it/s]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.56it/s]]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.55it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.86it/s]]\n",
      "100%|██████████| 770/770 [01:37<00:00,  7.90it/s]]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.62it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.72it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.72it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.70it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.83it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.83it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.79it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.79it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.85it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.83it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.79it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.76it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.77it/s]]\n",
      "100%|██████████| 770/770 [01:26<00:00,  8.89it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.82it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.84it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.72it/s]]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.72it/s]]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.85it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.78it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.75it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]it]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.75it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.78it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.79it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.80it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.81it/s]it]\n",
      "100%|██████████| 770/770 [01:29<00:00,  8.63it/s]it]\n",
      "100%|██████████| 770/770 [01:33<00:00,  8.21it/s]it]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.48it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.77it/s]it]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.75it/s]it]\n",
      "100%|██████████| 770/770 [01:28<00:00,  8.73it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.76it/s]it]\n",
      "100%|██████████| 770/770 [01:27<00:00,  8.75it/s]]  \n",
      "100%|██████████| 770/770 [01:28<00:00,  8.74it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.42it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.38it/s]]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.49it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.41it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.39it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.43it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.41it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.40it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.41it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.40it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.35it/s]]\n",
      "100%|██████████| 770/770 [01:33<00:00,  8.25it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.34it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.32it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.31it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.29it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.28it/s]]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.18it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.28it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.29it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.30it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.28it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.29it/s]]\n",
      "100%|██████████| 770/770 [01:32<00:00,  8.31it/s]]\n",
      "100%|██████████| 770/770 [01:33<00:00,  8.27it/s]]\n",
      "100%|██████████| 770/770 [01:33<00:00,  8.27it/s]]\n",
      "100%|██████████| 770/770 [01:34<00:00,  8.18it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.40it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.43it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.42it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.40it/s]]\n",
      "100%|██████████| 770/770 [01:31<00:00,  8.45it/s]]\n",
      "100%|██████████| 770/770 [01:30<00:00,  8.46it/s]]\n",
      "100%|██████████| 100/100 [2:30:03<00:00, 90.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted with provided ground truth data.\n",
      "Best parameters are:\n",
      "{'category': 2.903764967645502, 'paper': 0.6323336051521776, 'text': 2.1479318697981338, 'alpha': 0.3737468123409873, 'rrf': 0, 'k': 68}\n",
      "Best score was:\n",
      "0.5116094619666043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_ranges = {\n",
    "    'category': (0.0, 3.0),\n",
    "    'paper': (0.0, 3.0),\n",
    "    'text': (0.0, 3.0),\n",
    "    'alpha': (0.0, 1.0),\n",
    "    'rrf': (False, True),\n",
    "    'k': (30, 100)\n",
    "}\n",
    "ssc_rag.hybsearch_fit(ground_truth=ssc_gt_docs, param_ranges=param_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 0.08962309625236509,\n",
       " 'paper': 1.5419571656285616,\n",
       " 'text': 1.0558143115463618}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best minsearch parameters\n",
    "ssc_rag.boost_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 388.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6506493506493507, 'mmr': 0.4196438878581736}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(ssc_gt_docs, lambda q: ssc_rag.minsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost_dict': {'category': 2.903764967645502,\n",
       "  'paper': 0.6323336051521776,\n",
       "  'text': 2.1479318697981338},\n",
       " 'alpha': 0.3737468123409873,\n",
       " 'rrf': 0,\n",
       " 'k': 68}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hybsearch parameters\n",
    "ssc_h_best_params = {\n",
    "    \"boost_dict\":ssc_rag.h_boost_dict,\n",
    "    \"alpha\":ssc_rag.alpha,\n",
    "    \"rrf\":ssc_rag.rrf,\n",
    "    \"k\":ssc_rag.k\n",
    "}\n",
    "ssc_h_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [01:35<00:00,  8.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.7571428571428571, 'mmr': 0.5116094619666043}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation after optimization\n",
    "evaluate(ssc_gt_docs, lambda q: ssc_rag.hybsearch(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc_params_file = os.path.join(project_path, 'src', 'parameters', 'ssc_best_params.json')\n",
    "with open(ssc_params_file, \"w\") as file:\n",
    "    json.dump(ssc_h_best_params, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
